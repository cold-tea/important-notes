AGGREGATE FUNCTION -->>
	Return single value and works in a row.
	Eg: min, max, avg etc.
	
SUBQUERIES -->>
	Can be applied on SELECT, WHERE and FROM keywords
	Types
		Single Valued subqueries - Return single value (Can be applied on where = )
		Multiple Valued subqueries - Return multiple values (Can be applied on where in)
		Correlated subqueries - subqueries referencing the table or table alias from enclosing scope
		Multicolumn subqueries - subqueries returning more than one column
		Inline views - query used as a table providing the alias and performing further actions
		
INDEXES -->>
	Scanning table with millions of rows are often time consuming..
	Indexes are those schema objects which increments the performance of sql queries
	The most famous way of indexing is call B-Tree indexing. Where objects are stored in tree structure
	For say if index is create in salary column then the rows from value 1000 - 5000 will be stored in one leaf, 5000-10000 in another leaf and so on.
	Eg:
		CREATE INDEX index_name on table_name(column_name)
	Index referencing more than one column is called composite index.
	If multiple indexes are created for certain table then it will decrease the performance such that the DML operations performed should again recalculate where those value should be placed
	Explaing plan feature can be used to evaluate whether the indexes are being used or not during query execution

DATA DICTIONARY -->>
	USER_{name} - These view contains the info about the objects owned by the current connected user
	ALL_{name} - These view contains the info about the objects owned by the current user and those objects for which the user is given permission
	DBA_{name} - These view contains the info about all objects for all users
	DICT - This view has the metadata regarding all the views available as oracle data dictionary
	V${name} - These view has the dynamic info about various actions and are used primarily by adminstrators
				V$SESSION, V$SQLAREA, V$LOCK, V$INSTANCE etc.
				
TRANSACTIONS -->>
	COMMIT -
		Commit will commit the transactions made
		Rollback will rollback the changes made after last commit
		The record that is being modified in one session and not yet been committed will be locked such that other session cannot modify it
		There is another keyword called savepoint which marks the point of transaction and the rollback can be performed upto that point.
		syntax -
			(queries.......);   savepoint s1;  (queries.......);   rollback to s1;    -- this will rollback the transaction upto the savepoint s1
	
	
SEQUENCES -->>
	Database object used to generate unique objects
	syntax - 
		create sequence seq_name minvalue 1 maxvalue 99999 start with 1 increment by 1 cache 20
		cache will load the given integer into the memory to optimize the performance
	sequence_name.currval - current value in sequence, sequence.nextval - next value in sequence
	

IDENTITY COLUMNS -->>
	These column can be thought as built in columns with embedded sequence
	Types -
		GENERATED ALWAYS AS IDENTITY     -    If custom value is inserted then it will throw error
		GENERATED BY DEFAULT AS IDENTITY    - If custom value is inserted then it will accept .. the value is only inserted as default if not specified
		GENERATED BY DEFAULT AS IDENTITY (START WITH 100 INCREMENT BY 100) 
		
TRIGGERS -->>
	Triggers execute themselves at certain system event
	Types 
		DML
		DDL
		System Events (startup, shutdown, error messages)
		User Events (logon, logoff etc)
	
SYNONYMS -->>
	Synonyms are alternative names for database objects like table, views etc.
	syntax	
		create or replace synonym syn_name for (table_name/view_name etc).
		create or replace public synonym syn_name for (table_name/view_name etc).
		
		
PARTITIONING -->>
	Allows oracle data to be subdivided in small parts
	Tables are split horizontally
	Rows are divided and assigned to certain partitions based upon the condition on certain columns.
	Partitioning helps optimizer to find out in which partition the data reside and omit other partition from scanning.
	Partition vs Index
		If both are used then database optimizer might use index over partition.
	Types of table partitions
		List Partitioning -
			Here we have made four partitions. Values provides the condition analyzing which the records will be assigned to partition
			CREATE TABLE table_name 
			(columns.......)
			PARTITION BY LIST (column_name) (
				PARTITION parname_1 VALUES (...),
				PARTITION parname_2 VALUES (...),
				PARTITION parname_3 VALUES (...),
				PARTITION parname_4 VALUES (DEFAULT)    -- Value not matching any will be assigned here
			);
			
			Splitting existing partition parname_4 into two partitions
			ALTER TABLE table_name SPLIT PARTITION parname_4 VALUES (....)
			INTO (PARTITION parname_5, PARTITION parname_4);
		Range Partitioning -
			Here we have made four partitions. Values provides the condition analyzing which the records will be assigned to partition
			CREATE TABLE table_name 
			(columns.......)
			PARTITION BY RANGE (column_name) (
				PARTITION parname_1 VALUES LESS THAN (<something>),
				PARTITION parname_2 VALUES LESS THAN (<something>),
				PARTITION parname_3 VALUES LESS THAN (<something>),
				PARTITION parname_4 VALUES LESS THAN (<something>) 
			);
			
			Adding new partition
			ALTER TABLE table_name ADD PARTITION parname_5 VALUES LESS THAN (<something>)
		Hash Partitioning - 
			This method of partitioning is used when there is no specific way to partition the table.
			It just analyzes hash value and perform partitioning
			CREATE TABLE table_name 
			(columns......., PARTITION BY HASH (col_name)) PARTITIONS 4;
			
			ANALYZE TABLE table_name COMPUTE STATISTICS;   -- This will analyze the table and assign record to specific partition
			SELECT table_name, partition_name, num_rows FROM user_tab_partitions WHERE table_name = 'TABLE_NAME';
					-- This will list all partitions and provide info like number of rows etc.
		Interval Partitioning - 
		Composite Partitioning - 
		Automatic list Partitioning - 
		

		
------------------------------------------------------------ DATABASE ADMINSTRATION -------------------------------------
		
ARCHITECTURE -->>
	Made up of three parts - 
		Oracle instance
		Oracle database storage
		Oracle server processes (SPs)
		RDBMS
			Instance
				Process
					PMON
					SMON
					DbWn
					Ckpt
					LGWR
					ARCn
					Optional (ARCn, ASMB, RBAL, Others)
				Memort Structure
					SGA
						Data buffer cache
						Shared pool
						Redo log buffer
						Large pool
						Java pool
						Streams pool
					PGA
			Database
				Data files
				Control files
				Redo log files
				Archived redo log files
				Parameter files
				Password file
				Backup files
				Trace files
				Alert log file
				
				
BACKGROUND PROCESSES -->>
	DATABASE WRITER - 
		Writes data from data buffer cache to the disk
		Dirty  buffer = modified
		Cold buffer = not recently
		Writes the both types of buffers to the disk, such the buffer gets free space for other data.
		Can have more than one database writer according to the need.
		DB_WRITER_PROCESSES parameter can be used to configure more writers.
		When ? -- When a server process cannot find a clean reusable buffer, and when oracle needs to advance the checkpoint i.e,
			the oldest dirty buffer from which the database need to recover during failure i.e, in redo log file
			
	LOG WRITER -
		Redo log buffer is the cyclic buffer, 3 in count
		Responsible for writing from redo log buffer to redo log files
		When ? --
			When a user process commits a transaction
			When the redo log buffer is one-third full
			Before a DBWn process writes modified buffers to disk
			Every 3 seconds
			
	CHECKPOINT PROCESS -
		Checkpoint is a database event which synchronizes the modified data blocks in memory with the data files on disk
		It also updates the datafile header and control file with the latest checkpoint System Change Number (SCN)
		When ? --
			At each switch of the redo log files
			Once the number os seconds defined in the LOG_CHECKPOINT_TIMEOUT is reached
			Once the current redo log file reaches the size
				LOG_CHECKPOINT_INTERVAL * size of IO OS blocks
			Directly by the ALTER SYSTEM SWITCH LOGFILE command
			Directly with the ALTER SYSTEM CHECKPOINT command
			
	SMON (System Monitor) PROCESS -
		Performs recovery at the instance startup
		Clears the temporary unused segment
		
	PMON (Process Monitor) PROCESS - 
		Performs process recovery when a user process fails
			Cleans up the buffer cache
			Free resource that are used by the user process
		Restarts stopped running dispatchers and server processes
		Dynamically registers database service with network listeners
		
	RECO (Recoverer) PROCESS - 
		Used with the distributed database configuration
		Automatically resolves all in-doubt transactions
		
	ARCn (Archiver) PROCESS -
		Copy redo log files to a designated storage device after a log switch occurs
		Runs only in ARCHIVELOG mode
		LOG_ARCHIVE_MAX_PROCESS param to configure the number of archiver process
		
		
MEMORY STRUCTURES -->>
	SGA (Shared Global Area) 
		Program code (PL/SQL code, Java code)
		Cached data shared among users
		Redo log entries
		Information about currently connected sessions etc.
		This is shared across multiple users
		
		BUFFER CACHE -
			holds the copies of data blocks that are read from data files
			shared by all concurrent users
			number of buffers defined by DB_BLOCK_BUFFERS
			size of a buffer based on DB_BLOCK_SIZE
			stores the most recently used blocks
			Data must first come in buffer before the user can read it
			
		SHARED POOL -
			Library cache
				Contains statement text, parsed code and an execution plan, Contains one or more sql area
				Shared SQL area
					contains a parse tree and execution plan for a given SQL statement
			Data dictionary cache
				Contains table and column definitions and privileges
			Result cache
				It stores the result of sql query and the plsql query
				If same query is run multiple times then it gives back the same result
			Size of shared pool SHARED_POOL_SIZE param
			
		REDO LOG BUFFER -
			This is a circular buffer which stores the changes made to the database
			DML, DDLs etc..
			Useful during database recovery
			Size is defined by LOG_BUFFER
			
		LARGE POOL -
			This is an optional memory area which provide large memory allocations
			If not defined then will reduce performance as the shared pool is used instead
			Parallel query operations
			Oracle backup and restore operations
			Make heavy operations use large pool instead of shared pool
			
		JAVA POOL and STREAMS POOL - 
			Used to store java code and java object required for java virtual machine
			Size defined by JAVA_POOL_SIZE
			
			Used to Oracle streams to store buffered queue message and provide memory for oracle streams processes
			Size defined by STREAMS_POOL_SIZE
			
		KEEP BUFFER POOL -
			Data which is frequently accessed can be pinned in the keep buffer pool
			In case if buffer cache is full and the data is to be removed will cause the problem if that data is highly used
			To create keep buffer pool DB_KEEP_CACHE_SIZE
			
		RECYCLE BUFFER POOL -
			Recycle pool is reserved for large tables that experience full table scans that are unlikely to be reread or accessed rarely
			Size defined by DB_RECYCLE_CACHE_SIZE
			
		nK BUFFER CACHE -
			Is used to store oracle data blocks having different size then the default block size (8192k)
			Default block size is denoted by DB_BLOCK_SIZE
			Size defined by DB_NK_CACHE_SIZE
			Eg: DB_2K_CACHE_SIZE = 0M, DB_4K_CACHE_SIZE = 0M etc ...
			
		
	PGA (Program Global Area)
		This area of memory is not shared.
		Users have their own PGA to work in their session
		PGA contains private SQL area for each server processes for each user connection
			That private SQL will be stored in Shared SQL area inside library cache checking if all are running similary query
		Its a private memory region containing data and control information for a server process
		
		
DEDICATED VS SHARED SERVERS -->>
	Dedicated servers -
		One server process is spawned for each user connection
		Consumes lots of memory
		Greater performance
	Shared servers -
		Server processes are shared among multiple connections
		It provides scalability
		Here first the user request is handled through Dispatcher process and is stored in the request & response queues. Then from that shared process performs its actions.
		Nobody is using these servers nowadays.
		In shared servers PGA contains only stack space and SGA contains User global areas. Both are in PGA in case of dedicated servers.
		
	
		
		
ORACLE INSTANCE -->>
	Is loaded into the memory each time database starts (In memory nature)
	Contains shared memory caches (Shared pool, buffer cache, redo buffer etc.)
	Contains Oracle's background processes
	Instance will be removed from the memory once it is shut down (non persistent nature)
	
DATABASE STORAGE -->>
	This is the storage which contains oracle files to store the data
	This makes the physical oracle database
	Microsoft word and microsoft word file is analogous to oracle instance and oracle file
	Data storage is usually - Both are natively supported by oracle
		SAN -  Storage Area Netword (Accessed by fibre network)
		NAS -  Netword Attached Storage 
	Data can also be place in local disk (not recommended - single point of failure)	
		
		
SERVER PROCESSES (SPs) -->>
	Server processes are spawned when user is trying to connect to database.
	Each user will have the dedicated server process unless pooling is used with the help of middleware.
	It's role -
		verify the syntax of sql query that the user is trying to execute
		it then read data from disk and also load it in the buffer cache
		
		
		
---------------ORACLE INSTALLATION PROCESS -----------------------------------------
	Steps:
		i) Edit /etc/hosts file and add 	127.0.0.1	<eg:oel7.lab.local>	<eg:oel7>
			this is to resolve domain from ip and viceversa, run hostname command to resolve what to put in second parameter

		ii) Resolve oracle kernel parameters as well as the group that is to be added for the oracle functioning like groupadd -g oinstall, 				groupadd -g dba, useradd -g oinstall -G dba oracle passwd oracle... This all will be done by below command
				yum install oracle-rdbms-server-12cR1-preinstall
				yum install oracle-database-server-12cR2-preinstall
			group and user are stored in /etc/group and /etc/passwd file respectively. command -->> id oracle --- will also display
		iii) Now create directory where oracle is to be installed. For this login as root user and enter commands
			mkdir -p /u01/app/oracle    --- oracle binary file will be stored here i.e, oracle software
			chown -R oracle:oinstall /u01
			chmod -R 775 /u01

			mkdir -p /mnt/san_storage/oradata --- oracle datafiles, redofiles etc will be stored here i.e, datafiles
		iv) Now change /home/oracle/.bash_profile
			export ORACLE_HOSTNAME=oel7.lab.local i.e, hostname
			export ORACLE_UNQNAME=orcl
			export ORACLE_BASE=/u01/app/oracle
			export ORACLE_HOME=$ORACLE_BASE/product/12.1.0.2/dbhome_1
			export ORACLE_SID=orcl
			export PATH=/usr/sbin:$PATH
			export PATH=$ORACLE_HOME/bin:$PATH

		v) Now set SELINUX to be permissive, this will print warning instead of enforcing security
			/etc/selinux/config     SELINUX=permissive
			run command -->> setenforce permissive ---- to immediately show the effect otherwise restart to see the change
		vi) If network firewalls are up and running stop them so they don't interfere
			service iptables stop
			chkconfig iptables off
		vii) Create the folder where oracle is to be downloaded
			With root user - 
				mkdir -p /orasoft
				chown -R oracle:oinstall /orasoft

	After installation --
		Creating a database instance
			Goto dbhome/bin folder and run "netca"
			Go on and add the listener, default port of 1521 can be used as the listener's port
			After finishing it -
				run 'lsnrctl' command, after that 'status' command will show what listener is currently running
		Creating a database
			Database can also be created in manual for which we have to create everything like spfile (parameters) in dbs folder,
				database itself (
					create database orcl
					darafile '..../example.dbf' size 300m autoextend on
					sysaux datafile '............' ......... on
					default tablespace user_data datafile '............' 
					undo tablespace undotbs datafile '.....................'
					logfile group 1 '......./redo1.redo' size 100m,
							group 2 '......../redo2.redo' size 100m;
				) save this  sql in some location, then connect to idle instance of database with admin and then startup nomount
				  after this run that sql file and all other sql files, 
				datafiles etc...
				This method is hectic , so prefer below options
			Goto dbhome/bin folder and run "dbca"
			While creating database select advanced mode and do accordingly
			For simplicity Create as container database is not checked, if checked then pluggable database will be created too if selected accordingly
			Oracle enterprise manager is the web interface provided through which we can manage our database as administrator
			During the setup of recovery area checking the archiving will archive the redo logs automatically
			Storage area can be setup which must be the secured one
			After filling up all the required details, the database creation and the instance creation step will begin.
		view /etc/oratab file for all the services running in the host
			orcl:/u01/app/oracle/product/12.2.0/dbhome_1:N, here N means the instance will not run automatically after reboot
		
		
		
---------------- ORACLE LINUX FIXING SWAP SIZE ----------------------------------------------------------------

	1 check what swap size
	#swapon –s
	Filename                                Type            Size    Used    Priority
	/dev/xvda3                              partition       2097144 0       -1
	  
	2 Create a file that you’ll use for swap with dd command with   as root
	dd if=/dev/zero of={/swapfile path} bs={size of swap}  count=1048576
	Example:-
	[root@localhost]#dd if=/dev/zero of=/home/swapfile bs=6048 count=1048576
	Note :- Above command will be create the 6Gb swapfile on /home location as  swapfile
	3 Set up a Linux swap area
	#mkswap /home/swapfile
	4: Enabling the swap file
	#swapon /home/swapfile
	#swapon –a
	5 status of add swap
	[root@myrem12c em12cBP1]# swapon -s
	Filename                                Type            Size    Used    Priority
	/dev/xvda3                              partition       2097144 0       -1
	/home/swapfile                          file            6097144 0       -2
	6 Update /etc/fstab   (this must to be done )
	#vi /etc/fstab
	/home/swapfile        none             swap   sw      0 0  
	Note  :- Add above line ending with  the file otherwise ones you restart the server swap partition not be mounted to the system

	Then retry the installation
		
		
		
---------------------- USEFUL LINUX COMMANDS (CENTOS) --------------------------------	
	
	wget http://get.geo.opera.com/pub/opera/linux/1216/opera-12.16-1860.x86_64.rpm
	lsnrctl status;	lsnrctl start;	lsnrctl stop;
	lsnrctl > status; lsnrctl > start; lsnrctl > stop;
	via sqlplus >
		start and stop the instance -
			alter system register;   >> force instance to connect to the listener automatically
			shutdown - nomount - mount - open
			nomount - 
				only instance is started, not connected to the database, used for database creation and recovery purpose
			mount -
				taking the instance and associating with the database
				only the dba can access database at this stage, no user can access, still closed
				for enabling and disabling archive log mode
				for renaming data files etc.
				users cannot access the database at this stage
				adding, dropping, renamind redo log files
				performing database recovery
			open -
				all users can access the database
			shutdown immediate;	shutdown abort; shutdown normal OR shutdown;     >> stopping the database instance
			startup;   >> startup mount and open
			startup nomount;   >> startup database to nomount state. Instance is up but not linked to the database
			startup mount;
			startup open;   >> ready to receive the connections
		parameters related -
			show parameter sga_target;
			show parameter sga_; >> list all the params with sg_ text as substring
			alter system set sga_target=1000m scope=memory/spfile/both;  >> memory -- cleared after restart, spfile -- stored in spfile reflects after restart, both -- both
			create pfile='/home/oracle/my_pfile.ora' from spfile;    >> this will copy all the parameters from spfile so that we can view it
			Parameter file are of two type :
				pfile and spfile, pfile is stored as string whereas spfile is stored as binary
				pfile -> $ORACLE_HOME/dbs/init.ora
				spfile - > $ORACLE_HOME/dbs/spfile[sid].ora
		create user and permissions -
			create user user_name identified by password;   >> if connected then displays create session privilege error
			grant create session to user_name;    >> if create table is executed - insufficient privilege
			grant unlimited tablespace, create table to user_name; 
			drop user user_name;   >> only if the schema does not owns anything otherwise
			drop user user_name cascade;
			create role role_name;
			grant (roles.....) to role_name;
			grant role_name to user_name;
		data dictionary -
			v$logfile;    >> view all redo log files
			dba_data_files;    >> view data files, <file_name, tablespace_name> shows the datafile belonging to tablespace
			v$controlfile;		>> view control file.  >> if multiplexing is enabled then it will be stored in multiple places
			v$session;
			dba_tablespaces;
		troubleshoot using alert log -
			It contains all warnings, errors generated by oracle
			cd $ORACLE_BASE/diag/rdbms/orcl/orcl/trace   >> here alert_orcl.log
		storage - 
			tablespace is a collection of datafiles used as the storage
			dba_tablespaces -
				system - it is the tablespace where oracle data dictionary are stored.
			dba_data_files;    >> view data files, <file_name, tablespace_name> shows the datafile belonging to tablespace	
			create tablespace tbspc_name datafile '/mnt/san_storage/oradata/dfile01.dbf' size 20m autoextend on;
			drop tablespace tbspc_name including contents and datafiles;
		control files -
			The database control file maintains information about the physical structure of the database
			The control file is critical to recovering a data file because the control maintains the System Control Number (SNC) for each data file
			Multiplexing control file will eradicate the single point of failure issue
			CREATE CONTROLFILE is used to manually create a controlfile
			ALTER DATABASE BACKUP CONTROL FILE TO TRACE for backup
		
		
		
		
	